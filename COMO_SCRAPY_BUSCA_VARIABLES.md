# ğŸ” Â¿CÃ³mo Scrapy Busca las Variables del Spider?

## âœ… Respuesta Corta

**SÃ­, Scrapy busca esas variables por nombre** usando **reflexiÃ³n/introspecciÃ³n** de Python. Cuando ejecutas `scrapy crawl bcra`, Scrapy:

1. Busca el spider con `name = "bcra"`
2. Lee `start_urls` para saber quÃ© URLs scrapear
3. Lee `allowed_domains` para validar dominios
4. Usa estos valores automÃ¡ticamente

---

## ğŸ” Paso a Paso: CÃ³mo Scrapy Encuentra tu Spider

### **PASO 1: Ejecutas el Comando**

```bash
scrapy crawl bcra
```

### **PASO 2: Scrapy Lee `scrapy.cfg` y `settings.py`**

```python
# settings.py
SPIDER_MODULES = ["ingestor_scrapper.interface.spiders"]
```

Esto le dice a Scrapy **dÃ³nde buscar** los spiders.

### **PASO 3: Scrapy Busca TODAS las Clases que Heredan de `scrapy.Spider`**

Scrapy escanea el directorio `ingestor_scrapper/interface/spiders/` y busca:

```python
# Scrapy internamente hace algo como esto:
import importlib
import inspect

# 1. Importa todos los mÃ³dulos del directorio spiders
modules = importlib.import_module("ingestor_scrapper.interface.spiders")

# 2. Busca todas las clases que heredan de scrapy.Spider
for name, obj in inspect.getmembers(modules):
    if inspect.isclass(obj) and issubclass(obj, scrapy.Spider):
        # Â¡EncontrÃ³ un spider!
        spider_class = obj
```

### **PASO 4: Scrapy Lee el Atributo `name`**

```python
# Tu cÃ³digo:
class BcraSpider(scrapy.Spider):
    name = "bcra"  # â† Scrapy lee esto
```

Scrapy compara:

```python
# Scrapy internamente hace:
spider_name = BcraSpider.name  # Lee "bcra"
if spider_name == "bcra":  # â† "bcra" es lo que pediste en el comando
    # Â¡Este es el spider correcto!
    spider = BcraSpider()
```

### **PASO 5: Scrapy Lee `start_urls`**

```python
# Tu cÃ³digo:
start_urls = [BCRA_PRINCIPALES_VARIABLES_URL]  # â† Scrapy lee esto
```

Scrapy internamente hace:

```python
# Scrapy internamente hace:
urls = spider.start_urls  # Lee ["https://www.bcra.gob.ar/..."]
for url in urls:
    request = Request(url=url, callback=spider.parse)
    # Agrega las requests a la cola
```

### **PASO 6: Scrapy Lee `allowed_domains` (si existe)**

```python
# Tu cÃ³digo:
allowed_domains = BCRA_DOMAINS  # â† Scrapy lee esto
```

Scrapy usa esto para **validar** que solo scrapees dominios permitidos:

```python
# Scrapy internamente valida:
if request.url not in spider.allowed_domains:
    # Rechaza la request si el dominio no estÃ¡ permitido
    raise Exception(f"Domain not allowed: {request.url}")
```

---

## ğŸ¯ VisualizaciÃ³n: CÃ³mo Scrapy Busca los Atributos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TÃš EJECUTAS: scrapy crawl bcra                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY: Lee settings.py                                     â”‚
â”‚  SPIDER_MODULES = ["ingestor_scrapper.interface.spiders"]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY: Escanea el directorio spiders/                     â”‚
â”‚  Busca todas las clases que heredan de scrapy.Spider        â”‚
â”‚                                                               â”‚
â”‚  Encuentra:                                                  â”‚
â”‚  - BcraSpider(scrapy.Spider)                                â”‚
â”‚  - ScrapeThisSiteSpider(scrapy.Spider)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY: Lee atributos de clase usando reflexiÃ³n            â”‚
â”‚                                                               â”‚
â”‚  Para cada spider:                                           â”‚
â”‚    spider.name = ???  â† Busca este atributo                  â”‚
â”‚                                                               â”‚
â”‚  BcraSpider.name = "bcra"  â† âœ¨ Â¡EncontrÃ³ el correcto!       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY: Lee otros atributos de clase                        â”‚
â”‚                                                               â”‚
â”‚  spider.start_urls = ???      â† Lee start_urls               â”‚
â”‚  spider.allowed_domains = ??? â† Lee allowed_domains         â”‚
â”‚                                                               â”‚
â”‚  BcraSpider.start_urls = ["https://..."]                     â”‚
â”‚  BcraSpider.allowed_domains = ["bcra.gob.ar", ...]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCRAPY: Usa estos valores para iniciar el scraping          â”‚
â”‚                                                               â”‚
â”‚  for url in spider.start_urls:                               â”‚
â”‚      Request(url=url, callback=spider.parse)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» CÃ³mo Funciona la ReflexiÃ³n en Python

Scrapy usa **reflexiÃ³n/introspecciÃ³n** de Python para leer atributos de clase:

```python
# Ejemplo simplificado de cÃ³mo Scrapy lo hace:

class BcraSpider(scrapy.Spider):
    name = "bcra"
    start_urls = ["https://www.bcra.gob.ar/..."]

# Scrapy internamente:
spider_class = BcraSpider

# Lee atributos de clase:
spider_name = spider_class.name  # "bcra"
start_urls = spider_class.start_urls  # ["https://..."]
allowed_domains = getattr(spider_class, "allowed_domains", None)  # Lee si existe
```

### **Atributos de Clase vs Instancia**

```python
class BcraSpider(scrapy.Spider):
    # âœ… Atributo de CLASE (lo que Scrapy busca)
    name = "bcra"
    start_urls = ["https://..."]
    
    def __init__(self):
        # âŒ Atributo de INSTANCIA (Scrapy NO lo busca asÃ­)
        self.custom_value = "something"
```

**Scrapy busca atributos de clase** porque necesita leerlos **antes** de crear la instancia.

---

## ğŸ“‹ Variables que Scrapy Busca AutomÃ¡ticamente

| Variable | PropÃ³sito | Â¿Obligatorio? | Ejemplo |
|----------|-----------|-----------------|---------|
| **`name`** | Identificador Ãºnico del spider | âœ… **SÃ** | `name = "bcra"` |
| **`start_urls`** | URLs iniciales para scrapear | âœ… **SÃ** | `start_urls = ["https://..."]` |
| **`allowed_domains`** | Dominios permitidos | âš ï¸ Opcional | `allowed_domains = ["bcra.gob.ar"]` |
| **`custom_settings`** | ConfiguraciÃ³n especÃ­fica del spider | âš ï¸ Opcional | `custom_settings = {...}` |

### **Variables que Scrapy NO busca (opcionales)**

```python
class BcraSpider(scrapy.Spider):
    name = "bcra"
    start_urls = ["https://..."]
    
    # Estas son opcionales, Scrapy las ignora si no existen:
    allowed_domains = [...]  # Opcional
    custom_settings = {...}  # Opcional
    
    # Estas son mÃ©todos que TÃš defines:
    def parse(self, response):  # Scrapy llama este mÃ©todo
        ...
```

---

## ğŸ”§ CÃ³mo Funciona `scrapy crawl`

Cuando ejecutas `scrapy crawl bcra`, internamente Scrapy hace:

```python
# PseudocÃ³digo de cÃ³mo Scrapy funciona:

def crawl(spider_name):
    # 1. Encuentra el spider por nombre
    spider_class = find_spider_by_name(spider_name)  # Busca name = "bcra"
    
    # 2. Crea instancia del spider
    spider = spider_class()
    
    # 3. Lee start_urls de la clase (no de la instancia)
    urls = spider_class.start_urls
    
    # 4. Crea requests para cada URL
    for url in urls:
        request = Request(url=url, callback=spider.parse)
        scheduler.add(request)
    
    # 5. Inicia el engine
    engine.start()
```

---

## ğŸ“ Resumen

| Pregunta | Respuesta |
|----------|-----------|
| **Â¿Scrapy busca las variables?** | âœ… SÃ­, usando reflexiÃ³n/introspecciÃ³n |
| **Â¿CÃ³mo las busca?** | Lee atributos de clase (ej: `Spider.name`) |
| **Â¿CuÃ¡ndo las busca?** | Antes de crear la instancia del spider |
| **Â¿DÃ³nde las busca?** | En el directorio `SPIDER_MODULES` |
| **Â¿QuÃ© busca?** | Clases que heredan de `scrapy.Spider` |
| **Â¿QuÃ© atributos lee?** | `name`, `start_urls`, `allowed_domains`, etc. |

---

## ğŸ’¡ Conceptos Clave

### **1. ConvenciÃ³n sobre ConfiguraciÃ³n**

Scrapy usa **convenciÃ³n sobre configuraciÃ³n**:
- Si defines `name = "bcra"`, Scrapy lo encuentra automÃ¡ticamente
- No necesitas registrar el spider en ningÃºn archivo de configuraciÃ³n
- Scrapy usa **nombres de atributos especÃ­ficos** (`name`, `start_urls`)

### **2. Atributos de Clase**

```python
# âœ… Scrapy busca esto (atributo de clase):
class BcraSpider(scrapy.Spider):
    name = "bcra"  # â† Atributo de CLASE

# âŒ Scrapy NO busca esto (atributo de instancia):
def __init__(self):
    self.name = "bcra"  # â† Atributo de INSTANCIA
```

### **3. Herencia de `scrapy.Spider`**

Scrapy solo busca clases que heredan de `scrapy.Spider`:

```python
# âœ… Scrapy lo encuentra:
class BcraSpider(scrapy.Spider):
    name = "bcra"

# âŒ Scrapy lo ignora:
class MiClase:  # No hereda de scrapy.Spider
    name = "bcra"
```

---

## ğŸš€ Ejemplo PrÃ¡ctico

Imagina que tienes dos spiders:

```python
# bcra_spider.py
class BcraSpider(scrapy.Spider):
    name = "bcra"
    start_urls = ["https://www.bcra.gob.ar/..."]

# scrapethissite_spider.py
class ScrapeThisSiteSpider(scrapy.Spider):
    name = "scrapethissite"
    start_urls = ["https://www.scrapethissite.com/..."]
```

Cuando ejecutas `scrapy crawl bcra`:

1. Scrapy busca en `ingestor_scrapper/interface/spiders/`
2. Encuentra `BcraSpider` y `ScrapeThisSiteSpider`
3. Lee `BcraSpider.name = "bcra"` âœ…
4. Lee `ScrapeThisSiteSpider.name = "scrapethissite"` (lo ignora)
5. Usa `BcraSpider.start_urls` para iniciar el scraping

---

## ğŸ“š DocumentaciÃ³n

Para mÃ¡s informaciÃ³n sobre cÃ³mo Scrapy busca spiders:

- [Scrapy Spider Discovery](https://docs.scrapy.org/en/latest/topics/spiders.html#spider-discovery)
- [Spider Attributes](https://docs.scrapy.org/en/latest/topics/spiders.html#spider-attributes)

